"""
ë‹¤ì´ì†Œëª° ê±´ê°•ì‹í’ˆ í¬ë¡¤ëŸ¬
"""
from selenium.webdriver.common.by import By
from driver_setup import create_driver, quit_driver
from utils import *
from config import DAISO_CONFIG, DAISO_HEALTH_FOOD
from tqdm import tqdm
import traceback
import re

logger = setup_logger('daiso_health', 'daiso_health.log')

def extract_rating_from_text(text):
    """'ë³„ì  4.8ì ' í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
    match = re.search(r'ë³„ì \s*([\d.]+)ì ', text)
    if match:
        return float(match.group(1))
    return None

def extract_review_count(text):
    """'5,710 ê±´ ì‘ì„±' í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
    match = re.search(r'([\d,]+)', text.strip())
    if match:
        return int(match.group(1).replace(',', ''))
    return 0

def build_health_category_url(large_code, middle_code, sub_code):
    """ê±´ê°•ì‹í’ˆ ì¹´í…Œê³ ë¦¬ URL ìƒì„±

    êµ¬ì¡°: /ds/exhCtgr/{ëŒ€ë¶„ë¥˜ì½”ë“œ}/{ì¤‘ë¶„ë¥˜ì½”ë“œ}/{ì†Œë¶„ë¥˜ì½”ë“œ}
    ì˜ˆ: /ds/exhCtgr/CTGR_00022/CTGR_01020/CTGR_01024
    """
    base = DAISO_CONFIG['base_url']
    return f"{base}/ds/exhCtgr/{large_code}/{middle_code}/{sub_code}"

def crawl_health_category(driver, main_category, sub_category_name, large_code, middle_code, sub_code, max_products=50):
    """ê±´ê°•ì‹í’ˆ ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ í¬ë¡¤ë§"""

    products = []
    url = build_health_category_url(large_code, middle_code, sub_code)
    full_category = f"{main_category}/{sub_category_name}"

    try:
        logger.info(f"ì¹´í…Œê³ ë¦¬ ì ‘ì†: {full_category} - {url}")
        driver.get(url)
        random_delay(3, 5)

        # í˜ì´ì§€ ìŠ¤í¬ë¡¤
        scroll_page(driver, scroll_pause=1, max_scrolls=10)

        # ìƒí’ˆ ì¹´ë“œ ì°¾ê¸°
        selectors = [
            '.product-card',
            '.swiper-slide',
            'div[class*="product-card"]',
        ]

        product_elements = []
        for selector in selectors:
            product_elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if len(product_elements) > 0:
                logger.info(f"ì„ íƒì '{selector}' ì‚¬ìš©, {len(product_elements)}ê°œ ë°œê²¬")
                break

        if len(product_elements) == 0:
            logger.warning(f"ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_category}")
            return products

        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        product_elements = product_elements[:max_products]

        for idx, elem in enumerate(tqdm(product_elements, desc=f"{full_category[:20]}")):
            try:
                driver.execute_script("arguments[0].scrollIntoView(true);", elem)
                random_delay(0.3, 0.7)

                product_data = {
                    'site': 'ë‹¤ì´ì†Œ',
                    'main_category': main_category,
                    'sub_category': sub_category_name,
                    'crawled_at': get_timestamp(),
                    'brand': 'ë‹¤ì´ì†Œ',
                }

                # ìƒí’ˆëª…
                try:
                    name_elem = elem.find_element(By.CSS_SELECTOR, '.product-title')
                    product_data['product_name'] = name_elem.text.strip()
                except:
                    product_data['product_name'] = ''

                # ê°€ê²©
                try:
                    price_elem = elem.find_element(By.CSS_SELECTOR, '.price-value .value')
                    price_text = price_elem.text.strip()
                    product_data['price'] = int(price_text.replace(',', ''))
                except:
                    product_data['price'] = None

                # ì›ê°€, í• ì¸ìœ¨
                product_data['original_price'] = None
                product_data['discount_rate'] = ''

                # í‰ì 
                try:
                    rating_elem = elem.find_element(By.CSS_SELECTOR, '.rating-star .hiddenText')
                    rating_text = rating_elem.text.strip()
                    product_data['rating'] = extract_rating_from_text(rating_text)
                except:
                    product_data['rating'] = None

                # ë¦¬ë·° ìˆ˜
                try:
                    review_elem = elem.find_element(By.CSS_SELECTOR, '.star-detail')
                    review_text = review_elem.text.strip()
                    product_data['review_count'] = extract_review_count(review_text)
                except:
                    product_data['review_count'] = 0

                # ì´ë¯¸ì§€ URL
                try:
                    img_elem = elem.find_element(By.CSS_SELECTOR, 'img')
                    img_src = img_elem.get_attribute('src')
                    if not img_src:
                        srcset = img_elem.get_attribute('srcset')
                        if srcset:
                            img_src = srcset.split()[0]
                    product_data['image_url'] = img_src if img_src else ''
                except:
                    product_data['image_url'] = ''

                # ìƒí’ˆ URL
                try:
                    link_elem = elem.find_element(By.CSS_SELECTOR, '.detail-link')
                    href = link_elem.get_attribute('href')
                    if href and not href.startswith('http'):
                        href = DAISO_CONFIG['base_url'] + href
                    product_data['product_url'] = href if href else ''
                except:
                    product_data['product_url'] = ''

                # ë°ì´í„° ì¶”ê°€
                if product_data['product_name']:
                    products.append(product_data)

            except Exception as e:
                logger.warning(f"ìƒí’ˆ {idx+1} ì¶”ì¶œ ì‹¤íŒ¨: {str(e)[:100]}")
                continue

        logger.info(f"ì¹´í…Œê³ ë¦¬ '{full_category}' ì™„ë£Œ: {len(products)}ê°œ ìˆ˜ì§‘")

    except Exception as e:
        logger.error(f"ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        logger.error(traceback.format_exc())

    return products

def select_categories():
    """ì‚¬ìš©ìê°€ í¬ë¡¤ë§í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ"""

    print("\n" + "=" * 70)
    print("ë‹¤ì´ì†Œ ê±´ê°•ì‹í’ˆ ì¹´í…Œê³ ë¦¬ ì„ íƒ")
    print("=" * 70)

    health_data = DAISO_HEALTH_FOOD["ê±´ê°•ì‹í’ˆ"]
    sub_categories = health_data['ì†Œë¶„ë¥˜']

    print("\nğŸ’Š ê±´ê°•ì‹í’ˆ ì†Œë¶„ë¥˜:")
    sub_list = list(sub_categories.items())
    for i, (code, name) in enumerate(sub_list, 1):
        print(f"  {i}. {name}")
    print(f"  0. ì „ì²´ í¬ë¡¤ë§ (9ê°œ ì†Œë¶„ë¥˜)")

    choice = input(f"\ní¬ë¡¤ë§í•  ì¹´í…Œê³ ë¦¬ ë²ˆí˜¸ (0-{len(sub_list)}): ").strip()

    if choice == '0':
        return 'all'

    try:
        idx = int(choice) - 1
        if 0 <= idx < len(sub_list):
            return sub_list[idx]
    except:
        pass

    print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ì „ì²´ í¬ë¡¤ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
    return 'all'

def crawl_daiso_health():
    """ë‹¤ì´ì†Œ ê±´ê°•ì‹í’ˆ í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜"""

    logger.info("=" * 60)
    logger.info("ë‹¤ì´ì†Œ ê±´ê°•ì‹í’ˆ í¬ë¡¤ë§ ì‹œì‘")
    logger.info("=" * 60)

    driver = None
    all_products = []

    try:
        # ì¹´í…Œê³ ë¦¬ ì„ íƒ
        selected = select_categories()

        # ë“œë¼ì´ë²„ ìƒì„±
        logger.info("Chrome ë“œë¼ì´ë²„ ìƒì„± ì¤‘...")
        driver = create_driver()
        logger.info("ë“œë¼ì´ë²„ ìƒì„± ì™„ë£Œ")

        health_data = DAISO_HEALTH_FOOD["ê±´ê°•ì‹í’ˆ"]
        large_code = health_data['ëŒ€ë¶„ë¥˜ì½”ë“œ']
        middle_code = health_data['ì¤‘ë¶„ë¥˜ì½”ë“œ']
        max_products = DAISO_CONFIG['max_products_per_category']

        # í¬ë¡¤ë§ ì‹¤í–‰
        if selected == 'all':
            # ì „ì²´ í¬ë¡¤ë§
            logger.info(f"\n{'='*20} ê±´ê°•ì‹í’ˆ ì „ì²´ {'='*20}")
            for sub_code, sub_name in health_data['ì†Œë¶„ë¥˜'].items():
                products = crawl_health_category(
                    driver, "ê±´ê°•ì‹í’ˆ", sub_name, large_code, middle_code, sub_code, max_products
                )
                all_products.extend(products)
                random_delay(2, 3)
        else:
            # íŠ¹ì • ì†Œë¶„ë¥˜ë§Œ
            sub_code, sub_name = selected
            logger.info(f"\n{'='*20} ê±´ê°•ì‹í’ˆ/{sub_name} {'='*20}")
            products = crawl_health_category(
                driver, "ê±´ê°•ì‹í’ˆ", sub_name, large_code, middle_code, sub_code, max_products
            )
            all_products.extend(products)

        # ë°ì´í„° ì €ì¥
        if all_products:
            date_str = get_date_string()
            filename = f'daiso_health_{date_str}.csv'
            filepath = save_to_csv(all_products, filename)
            logger.info(f"\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            logger.info(f"âœ… ì´ {len(all_products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘")

            # í†µê³„
            stats = {}
            for p in all_products:
                sub = p['sub_category']
                stats[sub] = stats.get(sub, 0) + 1

            logger.info("\n=== ì¹´í…Œê³ ë¦¬ë³„ ìˆ˜ì§‘ í˜„í™© ===")
            for cat, count in sorted(stats.items()):
                logger.info(f"  - {cat}: {count}ê°œ")

            print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘")
            print(f"ğŸ“ íŒŒì¼: {filepath}")
        else:
            logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("\nâš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        print(f"\nâŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    finally:
        if driver:
            logger.info("ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
            quit_driver(driver)
            logger.info("ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")

    return all_products

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ë‹¤ì´ì†Œëª° ê±´ê°•ì‹í’ˆ í¬ë¡¤ëŸ¬")
    print("=" * 70)
    print("\nğŸ’Š ê±´ê°•ì‹í’ˆ ì¹´í…Œê³ ë¦¬ (9ê°œ ì†Œë¶„ë¥˜):")
    health_data = DAISO_HEALTH_FOOD["ê±´ê°•ì‹í’ˆ"]
    for code, name in health_data['ì†Œë¶„ë¥˜'].items():
        print(f"  â€¢ {name}")
    print("\nâš ï¸  ì£¼ì˜: êµìœ¡/ì—°êµ¬ ëª©ì ì…ë‹ˆë‹¤.")
    print("=" * 70)

    input("\nì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    crawl_daiso_health()
