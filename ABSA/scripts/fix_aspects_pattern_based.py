"""
Aspect ë¶„ë¥˜ ì˜¤ë¥˜ë¥¼ íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ìˆ˜ì •
1. 100ê°œ ìƒ˜í”Œ GPT-5 ê²€ì‚¬ â†’ ì˜¤ë¶„ë¥˜ íŒ¨í„´ ì¶”ì¶œ
2. íŒ¨í„´ ê¸°ë°˜ìœ¼ë¡œ ì „ì²´ ë¦¬ë·° ìˆ˜ì •
"""

import sys
import os
import json
import re
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict
from openai import OpenAI

project_root = Path(__file__).parent.parent
aspect_dir = project_root / "data" / "raw" / "by_aspect"

ASPECTS = [
    "ë°°ì†¡/í¬ì¥", "í’ˆì§ˆ/ë¶ˆëŸ‰", "ê°€ê²©/ê°€ì„±ë¹„", "ì‚¬ìš©ê°/ì„±ëŠ¥",
    "ë””ìì¸", "ì¬ì§ˆ/ëƒ„ìƒˆ", "CS/ì‘ëŒ€", "ì¬êµ¬ë§¤", "ìƒ‰ìƒ/ë°œìƒ‰", "ìš©ëŸ‰/íœ´ëŒ€"
]

FILE_TO_ASPECT = {
    "ë°°ì†¡_í¬ì¥": "ë°°ì†¡/í¬ì¥",
    "í’ˆì§ˆ": "í’ˆì§ˆ/ë¶ˆëŸ‰",
    "ê°€ê²©_ê°€ì„±ë¹„": "ê°€ê²©/ê°€ì„±ë¹„",
    "ì‚¬ìš©ê°_ì„±ëŠ¥": "ì‚¬ìš©ê°/ì„±ëŠ¥",
    "ë””ìì¸": "ë””ìì¸",
    "ì¬ì§ˆ_ëƒ„ìƒˆ": "ì¬ì§ˆ/ëƒ„ìƒˆ",
    "CS_ì‘ëŒ€": "CS/ì‘ëŒ€",
    "ì¬êµ¬ë§¤": "ì¬êµ¬ë§¤",
    "ìƒ‰ìƒ_ë°œìƒ‰": "ìƒ‰ìƒ/ë°œìƒ‰",
    "ìš©ëŸ‰_íœ´ëŒ€": "ìš©ëŸ‰/íœ´ëŒ€"
}

ASPECT_TO_FILE = {v: k for k, v in FILE_TO_ASPECT.items()}

# ê° aspectë³„ í•µì‹¬ í‚¤ì›Œë“œ (ê¸°ë³¸)
ASPECT_KEYWORDS = {
    "ë°°ì†¡/í¬ì¥": ['ë°°ì†¡', 'íƒë°°', 'í¬ì¥', 'ë„ì°©', 'ë°°ë‹¬', 'ëŠ¦', 'ë¹ ë¥´'],
    "í’ˆì§ˆ/ë¶ˆëŸ‰": ['ë¶ˆëŸ‰', 'í•˜ì', 'ê³ ì¥', 'íŒŒì†', 'ìœ í†µê¸°í•œ', 'í’ˆì§ˆ'],
    "ê°€ê²©/ê°€ì„±ë¹„": ['ê°€ê²©', 'ê°€ì„±ë¹„', 'ë¹„ì‹¸', 'ì‹¸', 'ì €ë ´', 'ë¹„ìš©', 'ê°’'],
    "ì‚¬ìš©ê°/ì„±ëŠ¥": ['ë°œë¦¼', 'í¡ìˆ˜', 'ì´‰ì´‰', 'ê±´ì¡°', 'ì§€ì†', 'íš¨ê³¼', 'ì‚¬ìš©ê°'],
    "ë””ìì¸": ['ë””ìì¸', 'ì˜ˆì˜', 'ì´ì˜', 'ëª»ìƒ', 'ì™¸ê´€', 'ëª¨ì–‘'],
    "ì¬ì§ˆ/ëƒ„ìƒˆ": ['ëƒ„ìƒˆ', 'í–¥', 'ì¬ì§ˆ', 'ì§ˆê°', 'í…ìŠ¤ì²˜'],
    "CS/ì‘ëŒ€": ['ê³ ê°ì„¼í„°', 'ì‘ëŒ€', 'í™˜ë¶ˆ', 'êµí™˜', 'ìƒë‹´', 'cs'],
    "ì¬êµ¬ë§¤": ['ì¬êµ¬ë§¤', 'ë˜ ì‚¬', 'ë‹¤ì‹œ ì‚¬', 'ì¶”ì²œ', 'ë¹„ì¶”'],
    "ìƒ‰ìƒ/ë°œìƒ‰": ['ìƒ‰ìƒ', 'ë°œìƒ‰', 'ì»¬ëŸ¬', 'ìƒ‰ê¹”', 'ìƒ‰'],
    "ìš©ëŸ‰/íœ´ëŒ€": ['ìš©ëŸ‰', 'í¬ê¸°', 'ì‚¬ì´ì¦ˆ', 'íœ´ëŒ€', 'ì‘', 'ì ']
}


def extract_json(text: str) -> dict:
    if not text:
        return None
    json_match = re.search(r'\{[^{}]*\}', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group())
        except:
            pass
    try:
        return json.loads(text)
    except:
        return None


def check_aspect_with_gpt5(client: OpenAI, text: str, current_aspect: str) -> dict:
    """GPT-5ë¡œ aspect ê²€ì¦ ë° í‚¤ì›Œë“œ ì¶”ì¶œ"""
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ì‡¼í•‘ëª° ë¦¬ë·°ì˜ aspect ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë¦¬ë·°]
"{text}"

[í˜„ì¬ ë¶„ë¥˜]
{current_aspect}

[ê°€ëŠ¥í•œ aspect]
ë°°ì†¡/í¬ì¥, í’ˆì§ˆ/ë¶ˆëŸ‰, ê°€ê²©/ê°€ì„±ë¹„, ì‚¬ìš©ê°/ì„±ëŠ¥, ë””ìì¸, ì¬ì§ˆ/ëƒ„ìƒˆ, CS/ì‘ëŒ€, ì¬êµ¬ë§¤, ìƒ‰ìƒ/ë°œìƒ‰, ìš©ëŸ‰/íœ´ëŒ€

[ì‘ì—…]
1. í˜„ì¬ ë¶„ë¥˜ê°€ ì˜¬ë°”ë¥¸ì§€ íŒë‹¨
2. ì˜ëª»ëë‹¤ë©´ ì˜¬ë°”ë¥¸ aspectì™€ íŒë‹¨ ê·¼ê±° í‚¤ì›Œë“œ ì œì‹œ

[ì¶œë ¥ - JSON]
{{
  "is_correct": true/false,
  "correct_aspect": "ì˜¬ë°”ë¥¸ aspect",
  "keywords": ["íŒë‹¨ì— ì‚¬ìš©ëœ", "í‚¤ì›Œë“œë“¤"],
  "reason": "ê°„ë‹¨í•œ ì´ìœ "
}}"""

    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=300,
            response_format={"type": "json_object"}
        )
        result = extract_json(response.choices[0].message.content)
        if result:
            tokens = response.usage.prompt_tokens + response.usage.completion_tokens
            result["cost"] = tokens * 0.01 / 1000
        return result
    except Exception as e:
        print(f"Error: {e}")
        return None


def extract_patterns_from_samples(client: OpenAI, df: pd.DataFrame, current_aspect: str, sample_size: int = 100):
    """ìƒ˜í”Œì—ì„œ ì˜¤ë¶„ë¥˜ íŒ¨í„´ ì¶”ì¶œ"""
    if len(df) > sample_size:
        sample_df = df.sample(n=sample_size, random_state=42)
    else:
        sample_df = df

    patterns = defaultdict(list)  # {correct_aspect: [keywords]}
    misclassified = []
    total_cost = 0

    for idx, row in tqdm(sample_df.iterrows(), total=len(sample_df), desc="ìƒ˜í”Œ ë¶„ì„", leave=False):
        result = check_aspect_with_gpt5(client, row['text'], current_aspect)
        if result is None:
            continue

        total_cost += result.get("cost", 0)

        if not result.get("is_correct", True):
            correct_aspect = result.get("correct_aspect")
            keywords = result.get("keywords", [])

            if correct_aspect and correct_aspect in ASPECTS:
                patterns[correct_aspect].extend(keywords)
                misclassified.append({
                    'idx': idx,
                    'text': row['text'][:50],
                    'correct_aspect': correct_aspect,
                    'keywords': keywords
                })

    # í‚¤ì›Œë“œ ë¹ˆë„ ì •ë¦¬
    pattern_summary = {}
    for aspect, kws in patterns.items():
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ ê³„ì‚°
        kw_counts = defaultdict(int)
        for kw in kws:
            if kw and len(kw) >= 2:  # 2ê¸€ì ì´ìƒë§Œ
                kw_counts[kw.lower()] += 1
        # 2íšŒ ì´ìƒ ë“±ì¥í•œ í‚¤ì›Œë“œë§Œ
        pattern_summary[aspect] = [kw for kw, cnt in kw_counts.items() if cnt >= 2]

    return pattern_summary, misclassified, total_cost


def apply_patterns_to_all(df: pd.DataFrame, current_aspect: str, patterns: dict):
    """íŒ¨í„´ì„ ì „ì²´ ë°ì´í„°ì— ì ìš©"""
    moves = []

    for idx, row in df.iterrows():
        text = str(row['text']).lower()

        # ê° íŒ¨í„´ ì²´í¬
        for target_aspect, keywords in patterns.items():
            if target_aspect == current_aspect:
                continue

            # í‚¤ì›Œë“œ ë§¤ì¹­
            matched_keywords = [kw for kw in keywords if kw in text]

            if len(matched_keywords) >= 1:  # 1ê°œ ì´ìƒ í‚¤ì›Œë“œ ë§¤ì¹­
                moves.append({
                    'idx': idx,
                    'from': current_aspect,
                    'to': target_aspect,
                    'matched': matched_keywords,
                    'text': row['text'][:50]
                })
                break  # ì²« ë²ˆì§¸ ë§¤ì¹­ì—ì„œ ì¤‘ë‹¨

    return moves


def execute_moves(moves: list):
    """ì‹¤ì œë¡œ ë¦¬ë·° ì´ë™ ì‹¤í–‰"""
    # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
    dataframes = {}
    for filepath in aspect_dir.glob("*.csv"):
        if "correction" in filepath.name or "all_" in filepath.name:
            continue
        dataframes[filepath.stem] = pd.read_csv(filepath)

    # ì´ë™ ì‹¤í–‰
    move_log = []
    for move in moves:
        from_file = ASPECT_TO_FILE.get(move['from'])
        to_file = ASPECT_TO_FILE.get(move['to'])

        if not from_file or not to_file:
            continue
        if from_file not in dataframes or to_file not in dataframes:
            continue

        idx = move['idx']
        from_df = dataframes[from_file]

        if idx not in from_df.index:
            continue

        # í–‰ ë³µì‚¬
        row = from_df.loc[idx].copy()

        # aspect_labels ì—…ë°ì´íŠ¸
        old_labels = str(row.get('aspect_labels', ''))
        labels = [l.strip() for l in old_labels.split(',') if l.strip()]

        if move['from'] in labels:
            labels.remove(move['from'])
        if move['to'] not in labels:
            labels.append(move['to'])
        row['aspect_labels'] = ', '.join(labels)

        # íƒ€ê²Ÿì— ì¶”ê°€
        dataframes[to_file] = pd.concat([dataframes[to_file], row.to_frame().T], ignore_index=True)

        # ì†ŒìŠ¤ì—ì„œ ì‚­ì œ ë§ˆí‚¹
        dataframes[from_file] = dataframes[from_file].drop(idx)

        move_log.append(move)

    # ì €ì¥
    for name, df in dataframes.items():
        df = df.reset_index(drop=True)
        df.to_csv(aspect_dir / f"{name}.csv", index=False)

    return move_log


def main():
    print("="*70)
    print("Aspect ë¶„ë¥˜ ì˜¤ë¥˜ - íŒ¨í„´ ê¸°ë°˜ ì „ì²´ ìˆ˜ì •")
    print("="*70)

    if "OPENAI_API_KEY" not in os.environ:
        print("Error: OPENAI_API_KEY í•„ìš”")
        return

    client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

    csv_files = sorted(aspect_dir.glob("*.csv"))
    csv_files = [f for f in csv_files if "correction" not in f.name and "all_" not in f.name]

    all_patterns = {}
    all_moves = []
    total_cost = 0

    print(f"\nì´ {len(csv_files)}ê°œ íŒŒì¼ ì²˜ë¦¬\n")

    for filepath in tqdm(csv_files, desc="ì „ì²´ ì§„í–‰"):
        file_name = filepath.stem
        current_aspect = FILE_TO_ASPECT.get(file_name)

        if not current_aspect:
            continue

        df = pd.read_csv(filepath)
        print(f"\n{'='*50}")
        print(f"ğŸ“ {file_name} ({len(df)}ê±´)")
        print(f"{'='*50}")

        # 1. ìƒ˜í”Œì—ì„œ íŒ¨í„´ ì¶”ì¶œ
        print("1ë‹¨ê³„: ìƒ˜í”Œ 100ê°œ GPT-5 ë¶„ì„...")
        patterns, misclassified, cost = extract_patterns_from_samples(
            client, df, current_aspect, sample_size=100
        )
        total_cost += cost

        if not patterns:
            print(f"   ì˜¤ë¶„ë¥˜ íŒ¨í„´ ì—†ìŒ")
            continue

        print(f"   ë°œê²¬ëœ íŒ¨í„´:")
        for aspect, keywords in patterns.items():
            print(f"   â†’ {aspect}: {keywords[:5]}...")

        all_patterns[file_name] = patterns

        # 2. íŒ¨í„´ì„ ì „ì²´ì— ì ìš©
        print(f"\n2ë‹¨ê³„: ì „ì²´ {len(df)}ê±´ì— íŒ¨í„´ ì ìš©...")
        moves = apply_patterns_to_all(df, current_aspect, patterns)
        print(f"   ì´ë™ ëŒ€ìƒ: {len(moves)}ê±´")

        all_moves.extend(moves)

    # 3. ì‹¤ì œ ì´ë™ ì‹¤í–‰
    print(f"\n{'='*70}")
    print(f"3ë‹¨ê³„: ì´ {len(all_moves)}ê±´ ì´ë™ ì‹¤í–‰")
    print(f"{'='*70}")

    if all_moves:
        move_log = execute_moves(all_moves)
        print(f"âœ… {len(move_log)}ê±´ ì´ë™ ì™„ë£Œ")

        # ì´ë™ ìš”ì•½
        summary = defaultdict(lambda: defaultdict(int))
        for m in move_log:
            summary[m['from']][m['to']] += 1

        print("\n[ì´ë™ ìš”ì•½]")
        for from_asp, to_dict in summary.items():
            for to_asp, cnt in to_dict.items():
                print(f"   {from_asp} â†’ {to_asp}: {cnt}ê±´")

    print(f"\nì´ ë¹„ìš©: ${total_cost:.4f}")

    # ë¡œê·¸ ì €ì¥
    log_path = aspect_dir / "aspect_pattern_corrections.json"
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump({
            'patterns': {k: {a: list(kws) for a, kws in v.items()} for k, v in all_patterns.items()},
            'moves': all_moves[:100],  # ìƒìœ„ 100ê°œë§Œ
            'total_moves': len(all_moves),
            'cost': total_cost
        }, f, ensure_ascii=False, indent=2)
    print(f"ë¡œê·¸ ì €ì¥: {log_path}")


if __name__ == "__main__":
    main()
