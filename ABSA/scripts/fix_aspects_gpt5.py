"""
ëª¨ë“  ë¦¬ë·°ì˜ aspect ë¶„ë¥˜ ì˜¤ë¥˜ë¥¼ GPT-5ë¡œ ìˆ˜ì •
- ê° íŒŒì¼ì˜ ë¦¬ë·°ê°€ í•´ë‹¹ aspectì— ë§ëŠ”ì§€ ê²€ì¦
- ì˜ëª»ëœ aspectëŠ” ì˜¬ë°”ë¥¸ íŒŒì¼ë¡œ ì´ë™
"""

import sys
import os
import json
import re
import pandas as pd
from pathlib import Path
from tqdm import tqdm
from openai import OpenAI

project_root = Path(__file__).parent.parent
aspect_dir = project_root / "data" / "raw" / "by_aspect"

ASPECTS = [
    "ë°°ì†¡/í¬ì¥",
    "í’ˆì§ˆ/ë¶ˆëŸ‰",
    "ê°€ê²©/ê°€ì„±ë¹„",
    "ì‚¬ìš©ê°/ì„±ëŠ¥",
    "ì‚¬ì´ì¦ˆ/í˜¸í™˜",
    "ë””ìì¸",
    "ì¬ì§ˆ/ëƒ„ìƒˆ",
    "CS/ì‘ëŒ€",
    "ì¬êµ¬ë§¤",
    "ìƒ‰ìƒ/ë°œìƒ‰",
    "ìš©ëŸ‰/íœ´ëŒ€"
]

# íŒŒì¼ëª…ê³¼ aspect ë§¤í•‘
FILE_TO_ASPECT = {
    "ë°°ì†¡_í¬ì¥": "ë°°ì†¡/í¬ì¥",
    "í’ˆì§ˆ": "í’ˆì§ˆ/ë¶ˆëŸ‰",
    "ê°€ê²©_ê°€ì„±ë¹„": "ê°€ê²©/ê°€ì„±ë¹„",
    "ì‚¬ìš©ê°_ì„±ëŠ¥": "ì‚¬ìš©ê°/ì„±ëŠ¥",
    "ë””ìì¸": "ë””ìì¸",
    "ì¬ì§ˆ_ëƒ„ìƒˆ": "ì¬ì§ˆ/ëƒ„ìƒˆ",
    "CS_ì‘ëŒ€": "CS/ì‘ëŒ€",
    "ì¬êµ¬ë§¤": "ì¬êµ¬ë§¤",
    "ìƒ‰ìƒ_ë°œìƒ‰": "ìƒ‰ìƒ/ë°œìƒ‰",
    "ìš©ëŸ‰_íœ´ëŒ€": "ìš©ëŸ‰/íœ´ëŒ€"
}

ASPECT_TO_FILE = {v: k for k, v in FILE_TO_ASPECT.items()}


def extract_json(text: str) -> dict:
    """ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
    if not text:
        return None
    json_match = re.search(r'\{[^{}]*\}', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group())
        except:
            pass
    try:
        return json.loads(text)
    except:
        return None


def build_aspect_check_prompt(review_text: str, current_aspect: str) -> str:
    """aspect ê²€ì¦ í”„ë¡¬í”„íŠ¸"""
    aspect_list = "\n".join([f"- {a}" for a in ASPECTS])

    return f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ì‡¼í•‘ëª° ë¦¬ë·°ì˜ aspect(ì¸¡ë©´) ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ë¦¬ë·°]
"{review_text}"

[í˜„ì¬ ë¶„ë¥˜ëœ aspect]
{current_aspect}

[ê°€ëŠ¥í•œ aspect ëª©ë¡]
{aspect_list}

[ì‘ì—…]
ì´ ë¦¬ë·°ê°€ í˜„ì¬ aspectì— ì˜¬ë°”ë¥´ê²Œ ë¶„ë¥˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

[íŒë‹¨ ê¸°ì¤€]
- ë°°ì†¡/í¬ì¥: ë°°ì†¡ ì†ë„, í¬ì¥ ìƒíƒœ, íƒë°° ê´€ë ¨
- í’ˆì§ˆ/ë¶ˆëŸ‰: ì œí’ˆ ë¶ˆëŸ‰, í•˜ì, ê³ ì¥, ìœ í†µê¸°í•œ
- ê°€ê²©/ê°€ì„±ë¹„: ê°€ê²©, ê°€ì„±ë¹„, ë¹„ì‹¸ë‹¤/ì‹¸ë‹¤
- ì‚¬ìš©ê°/ì„±ëŠ¥: ì‚¬ìš©ê°, íš¨ê³¼, ì„±ëŠ¥, ë°œë¦¼ì„±, ì§€ì†ë ¥
- ë””ìì¸: ë””ìì¸, ì™¸ê´€, ì˜ˆì˜ë‹¤/ëª»ìƒê²¼ë‹¤
- ì¬ì§ˆ/ëƒ„ìƒˆ: ì¬ì§ˆ, í–¥, ëƒ„ìƒˆ
- CS/ì‘ëŒ€: ê³ ê°ì„¼í„°, ì‘ëŒ€, í™˜ë¶ˆ, êµí™˜ ì„œë¹„ìŠ¤
- ì¬êµ¬ë§¤: ì¬êµ¬ë§¤ ì˜í–¥, ì¶”ì²œ ì—¬ë¶€
- ìƒ‰ìƒ/ë°œìƒ‰: ìƒ‰ìƒ, ë°œìƒ‰, ì»¬ëŸ¬
- ìš©ëŸ‰/íœ´ëŒ€: ìš©ëŸ‰, í¬ê¸°, íœ´ëŒ€ì„±

[ì¶œë ¥ í˜•ì‹ - JSONë§Œ]
{{
  "is_correct": true/false,
  "correct_aspect": "ì˜¬ë°”ë¥¸ aspect (í˜„ì¬ì™€ ê°™ìœ¼ë©´ í˜„ì¬ aspect)",
  "reason": "íŒë‹¨ ì´ìœ "
}}

ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”."""


def check_aspect_with_gpt5(client: OpenAI, text: str, current_aspect: str) -> dict:
    """GPT-5ë¡œ aspect ê²€ì¦"""
    prompt = build_aspect_check_prompt(text, current_aspect)

    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "user", "content": prompt}],
            max_completion_tokens=500,
            response_format={"type": "json_object"}
        )

        content = response.choices[0].message.content
        result = extract_json(content)

        if result is None:
            return None

        # Cost
        tokens_in = response.usage.prompt_tokens
        tokens_out = response.usage.completion_tokens
        result["cost"] = tokens_in * 0.005 / 1000 + tokens_out * 0.015 / 1000

        return result

    except Exception as e:
        print(f"Error: {e}")
        return None


def process_file_for_aspects(client: OpenAI, filepath: Path, sample_size: int = None) -> dict:
    """íŒŒì¼ì˜ aspect ë¶„ë¥˜ ê²€ì¦"""
    file_name = filepath.stem
    current_aspect = FILE_TO_ASPECT.get(file_name, file_name)

    df = pd.read_csv(filepath)

    # ìƒ˜í”Œë§ (ì „ì²´ê°€ ë„ˆë¬´ ë§ìœ¼ë©´)
    if sample_size and len(df) > sample_size:
        check_df = df.sample(n=sample_size, random_state=42)
    else:
        check_df = df

    misclassified = []
    total_cost = 0

    for idx, row in tqdm(check_df.iterrows(), total=len(check_df), desc=file_name, leave=False):
        result = check_aspect_with_gpt5(client, row['text'], current_aspect)

        if result is None:
            continue

        total_cost += result.get("cost", 0)

        if not result.get("is_correct", True):
            correct_aspect = result.get("correct_aspect", current_aspect)
            if correct_aspect != current_aspect and correct_aspect in ASPECTS:
                misclassified.append({
                    'df_idx': idx,
                    'original_idx': row.get('index', idx),
                    'text': row['text'][:60],
                    'current_aspect': current_aspect,
                    'correct_aspect': correct_aspect,
                    'reason': result.get('reason', '')
                })

    return {
        'file': file_name,
        'total': len(df),
        'checked': len(check_df),
        'misclassified': len(misclassified),
        'details': misclassified,
        'cost': total_cost
    }


def move_misclassified_reviews(results: list):
    """ì˜ëª» ë¶„ë¥˜ëœ ë¦¬ë·°ë¥¼ ì˜¬ë°”ë¥¸ íŒŒì¼ë¡œ ì´ë™"""
    # ê° íŒŒì¼ ë¡œë“œ
    dataframes = {}
    for filepath in aspect_dir.glob("*.csv"):
        if filepath.name.startswith("í’ˆì§ˆ_correction") or filepath.name.startswith("all_"):
            continue
        dataframes[filepath.stem] = pd.read_csv(filepath)

    moves = []

    for result in results:
        source_file = result['file']
        source_df = dataframes.get(source_file)

        if source_df is None:
            continue

        for item in result['details']:
            correct_aspect = item['correct_aspect']
            target_file = ASPECT_TO_FILE.get(correct_aspect)

            if target_file is None or target_file not in dataframes:
                continue

            df_idx = item['df_idx']
            if df_idx >= len(source_df):
                continue

            # ë¦¬ë·° ë°ì´í„° ë³µì‚¬
            row = source_df.loc[df_idx].copy()

            # aspect_labels ì—…ë°ì´íŠ¸
            old_labels = row.get('aspect_labels', '')
            if isinstance(old_labels, str):
                labels = [l.strip() for l in old_labels.split(',')]
            else:
                labels = []

            # í˜„ì¬ aspect ì œê±°, ìƒˆ aspect ì¶”ê°€
            current_aspect = FILE_TO_ASPECT.get(source_file)
            if current_aspect in labels:
                labels.remove(current_aspect)
            if correct_aspect not in labels:
                labels.append(correct_aspect)

            row['aspect_labels'] = ', '.join(labels)

            # íƒ€ê²Ÿ íŒŒì¼ì— ì¶”ê°€
            dataframes[target_file] = pd.concat([dataframes[target_file], row.to_frame().T], ignore_index=True)

            # ì†ŒìŠ¤ì—ì„œ ì œê±° í‘œì‹œ
            moves.append({
                'from': source_file,
                'to': target_file,
                'idx': df_idx,
                'text': item['text']
            })

    # ì´ë™ëœ ë¦¬ë·° ì†ŒìŠ¤ì—ì„œ ì‚­ì œ
    for move in moves:
        source_file = move['from']
        idx = move['idx']
        if idx in dataframes[source_file].index:
            dataframes[source_file] = dataframes[source_file].drop(idx)

    # ì €ì¥
    for file_name, df in dataframes.items():
        df = df.reset_index(drop=True)
        df.to_csv(aspect_dir / f"{file_name}.csv", index=False)

    return moves


def main():
    print("="*70)
    print("Aspect ë¶„ë¥˜ ì˜¤ë¥˜ ê²€ì¦ ë° ìˆ˜ì • (GPT-5)")
    print("="*70)

    if "OPENAI_API_KEY" not in os.environ:
        print("Error: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

    # ê° íŒŒì¼ì—ì„œ ìƒ˜í”Œ ê²€ì‚¬ (ì „ì²´ ê²€ì‚¬ëŠ” ë¹„ìš©ì´ ë„ˆë¬´ ë†’ìŒ)
    # íŒŒì¼ë‹¹ ìµœëŒ€ 100ê°œ ìƒ˜í”Œ
    SAMPLE_SIZE = 100

    results = []
    total_cost = 0
    total_misclassified = 0

    csv_files = sorted(aspect_dir.glob("*.csv"))
    csv_files = [f for f in csv_files if not f.name.startswith("í’ˆì§ˆ_correction") and not f.name.startswith("all_")]

    print(f"\níŒŒì¼ë‹¹ ìµœëŒ€ {SAMPLE_SIZE}ê°œ ìƒ˜í”Œ ê²€ì‚¬")
    print(f"ì´ {len(csv_files)}ê°œ íŒŒì¼\n")

    for filepath in tqdm(csv_files, desc="ì „ì²´ ì§„í–‰"):
        result = process_file_for_aspects(client, filepath, sample_size=SAMPLE_SIZE)
        results.append(result)
        total_cost += result.get('cost', 0)
        total_misclassified += result.get('misclassified', 0)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ê²€ì¦ ì™„ë£Œ")
    print("="*70)

    print(f"\n{'íŒŒì¼':<15} {'ê²€ì‚¬':>6} {'ì˜¤ë¶„ë¥˜':>8} {'ë¹„ìš©':>10}")
    print("-"*45)

    for r in results:
        print(f"{r['file']:<15} {r['checked']:>6} {r['misclassified']:>8} ${r['cost']:>8.4f}")

    print("-"*45)
    print(f"{'ì´ê³„':<15} {'':>6} {total_misclassified:>8} ${total_cost:>8.4f}")

    # ì˜¤ë¶„ë¥˜ ìƒì„¸ ì¶œë ¥
    if total_misclassified > 0:
        print(f"\n[ì˜¤ë¶„ë¥˜ ìƒì„¸ - ì´ {total_misclassified}ê±´]")
        for r in results:
            if r['misclassified'] > 0:
                print(f"\nğŸ“ {r['file']}")
                for item in r['details'][:5]:  # ìƒìœ„ 5ê°œë§Œ
                    print(f"  [{item['original_idx']}] {item['current_aspect']} â†’ {item['correct_aspect']}")
                    print(f"       {item['text']}...")
                if len(r['details']) > 5:
                    print(f"  ... ì™¸ {len(r['details'])-5}ê±´")

        # ì´ë™ í™•ì¸
        print("\nì˜¤ë¶„ë¥˜ëœ ë¦¬ë·°ë¥¼ ì˜¬ë°”ë¥¸ íŒŒì¼ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
        moves = move_misclassified_reviews(results)
        print(f"ì´ {len(moves)}ê±´ ì´ë™ ì™„ë£Œ")

    # ë¡œê·¸ ì €ì¥
    log_path = aspect_dir / "aspect_corrections_gpt5.json"
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nìˆ˜ì • ë¡œê·¸ ì €ì¥: {log_path}")


if __name__ == "__main__":
    main()
