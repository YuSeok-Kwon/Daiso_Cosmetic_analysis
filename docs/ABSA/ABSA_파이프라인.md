# ABSA 파이프라인 문서

## 프로젝트 개요

**목표:** 다이소 뷰티 리뷰 데이터에서 Aspect-Based Sentiment Analysis를 수행하여 '연착륙 스킨케어' 제품 발굴

**데이터 규모:**
- 전체 리뷰: ~300,000개
- 샘플링 데이터: 20,000개
- Golden Set: 430개

---

## 파이프라인 흐름도

```
┌─────────────────────────────────────────────────────────────────────┐
│                        ABSA 파이프라인                               │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  [1] 층화 샘플링                                                     │
│       ↓                                                             │
│  [2] GPT-4o-mini 1차 라벨링 (20,000개)                               │
│       ↓                                                             │
│  [3] 사람 직접 검증 → 오류 패턴 파악                                  │
│       ↓                                                             │
│  [4] 프롬프트 재수정                                                 │
│       ↓                                                             │
│  [5] GPT-4o vs GPT-4o-mini 비교 (수정된 프롬프트)                     │
│       ↓                                                             │
│  [6] GPT-4o Batch API로 20,000개 라벨링 ✅ (현재 완료)                │
│       ↓                                                             │
│  [7] 사람 직접 검수 (샘플링)                                         │
│       ↓                                                             │
│      ┌──────────┴──────────┐                                        │
│      ↓                     ↓                                        │
│  [7-1] 이상 없음       [7-2] 이상 있음                               │
│      ↓                     ↓                                        │
│  [8] 모델 선별          [3]으로 돌아가기                             │
│      ↓                                                             │
│  [9] 전체 리뷰 적용 (300,000개)                                      │
│      ↓                                                             │
│  [10] 연착륙 상품 분석                                               │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 단계별 상세 설명

### 1단계: 층화 샘플링 전략

**목적:** 전체 300,000개 리뷰에서 대표성 있는 20,000개 추출

**샘플링 데이터 컬럼:**
- `product_code`: 제품 코드
- `name`: 제품명
- `category_2`: 카테고리
- `rating`: 평점 (1~5)
- `text`: 리뷰 텍스트
- `order_id`: 주문 ID

**카테고리 분포 (category_2):**
| 카테고리 | 건수 | 비율 |
|----------|------|------|
| 기초스킨케어 | 7,718 | 38.6% |
| 립메이크업 | 2,343 | 11.7% |
| 베이스메이크업 | 2,080 | 10.4% |
| 아이메이크업 | 1,992 | 10.0% |
| 팩/마스크 | 1,926 | 9.6% |
| 치크/하이라이터 | 1,079 | 5.4% |
| 자외선차단제 | 924 | 4.6% |
| 클렌징/필링 | 758 | 3.8% |
| 립케어 | 449 | 2.2% |
| 기타 (남성 등) | 731 | 3.7% |

**평점 분포:**
| 평점 | 건수 | 비율 |
|------|------|------|
| 1점 | 1,925 | 9.6% |
| 2점 | 1,769 | 8.8% |
| 3점 | 6,000 | 30.0% |
| 4점 | 1,502 | 7.5% |
| 5점 | 8,804 | 44.0% |

**결과:** `data/raw/sampled_reviews_20k.csv`

---

### 2단계: GPT-4o-mini 1차 라벨링

**목적:** 빠르고 저렴하게 초기 라벨링 수행

**설정:**
- 모델: `gpt-4o-mini`
- 비용: ~$2.87 (20,000개 기준)
- 소요 시간: 약 2-3시간

**출력:**
- 전체 Sentiment (positive/neutral/negative)
- Aspect Labels (11개 카테고리)
- Confidence Score
- Evidence (근거 문장)

---

### 3단계: 사람 직접 검증 및 오류 패턴 파악

**Golden Set 구성:**
- Team 1: 148개
- Team 2: 137개
- Team 3: 145개
- **총 430개**

**주요 오류 패턴:**

| 혼동 패턴 | 빈도 | 원인 |
|----------|------|------|
| 색상/발색 → 사용감/성능 | 26회 (93%) | "발색" vs "발림" 혼동 |
| 배송/포장 → CS/응대 | 10회 | 배송 중 파손 vs 제품 결함 |
| 품질/퀄리티 → 사용감/성능 | 12회 | "퀄리티" 키워드 누락 |

---

### 4단계: 프롬프트 재수정

**개선 사항:**

1. **Aspect 혼동 방지 규칙 추가**
```
- 색상/발색: "발색, 색, 컬러, 톤" 키워드 → 무조건 색상/발색
- 사용감/성능: 발림성, 지속력, 커버력 → 사용감/성능
- "발색" ≠ "발림" 명시
```

2. **평점 기반 Sentiment 보조 판단**
```
- 1~2점: negative 가능성 높음
- 3점: neutral 가능성 높음
- 4~5점: positive 가능성 높음
```

3. **미분류 카테고리 추가**
```
- Confidence < 0.7이면 미분류로 처리
- 억지로 Aspect 추출하지 않음
```

4. **다이소 특화 규칙**
```
- 듀프 비교: "올리브영 XX랑 똑같다" → 가격/가성비 positive
- 품절 대란: "구하기 힘들어서 짜증 (5점)" → 재구매 positive
```

---

### 5단계: GPT-4o vs GPT-4o-mini 비교

**목적:** 수정된 프롬프트로 어떤 모델이 더 적합한지 평가

**평가 방법:**
- Golden Set (430개)으로 동일 조건 테스트
- 정확도 비교

**결과:**
| 모델 | Aspect 정확도 | Sentiment 정확도 | Both 정확도 |
|------|--------------|-----------------|-------------|
| GPT-4o-mini | 51.2% | 67.0% | 43.5% |
| GPT-4o | 67.6% | 72.1% | **58.3%** |

**비용 비교 (20,000개 기준, Batch API 50% 할인):**
| 모델 | 비용 | 정확도 |
|------|------|--------|
| GPT-4o-mini | $2.87 | 43.5% |
| GPT-4o | $95.70 | 58.3% |

**결론:**
- GPT-4o가 15%p 더 정확
- B2B 입점 제안 목적상 정확도가 중요 → **GPT-4o 채택**
- 정확한 라벨 1개당 추가 비용: ~44원 (사람 검수 비용 대비 저렴)

---

### 6단계: GPT-4o Batch API로 20,000개 라벨링 ✅

**현재 상태:** 진행 중 (병렬 처리)

**설정:**
- 모델: `gpt-4o`
- 방식: Batch API (50% 비용 절감)
- 병렬 처리: 2개 API 키 사용

**비용:**
| 구분 | 리뷰 수 | 비용 |
|------|---------|------|
| 기존 키 | 13,150개 | $62.92 |
| 새 키 | 6,850개 | $32.78 |
| **총합** | **20,000개** | **$95.70** |

**출력 파일:**
- `data/batch/worker1_results.csv`
- `data/batch/worker2_results.csv`
- `data/batch/pipeline_results_partial.csv`

---

### 7단계: 사람 직접 검수

**방법:**
- 랜덤 샘플 100~200개 추출
- 오류율 확인
- 특히 "미분류" 케이스, 낮은 confidence 케이스 집중 검토

**판단 기준:**
| 오류율 | 조치 |
|--------|------|
| < 10% | ✅ 7-1로 진행 (모델링) |
| 10~20% | ⚠️ 오류 패턴 분석 후 판단 |
| > 20% | ❌ 7-2로 진행 (프롬프트 재수정) |

#### 7-1: 이상 없음 → 8단계로 진행

#### 7-2: 이상 있음 → 3단계로 돌아가기
- 오류 패턴 재분석
- 프롬프트 재수정
- 재라벨링

---

### 8단계: 모델 선별

**후보 모델 비교:**

| 모델 | 장점 | 단점 | 추천도 |
|------|------|------|--------|
| **LSTM/BiLSTM** | 구조 단순, 학습 목적 적합 | 긴 문장 약함, 느림 | ⭐⭐ |
| **KoBERT** | 한국어 특화, 문맥 이해 강함 | GPU 필요, 무거움 | ⭐⭐⭐⭐ |
| **KoELECTRA** | 가볍고 빠름, 성능 우수 | - | ⭐⭐⭐⭐⭐ |
| **LightGBM + TF-IDF** | 매우 빠름, CPU 가능 | 문맥 이해 약함 | ⭐⭐⭐ |

**상세 비교:**

#### LSTM / BiLSTM
```
구조: Embedding → BiLSTM → Attention → Dense → Output

장점:
- 순차 데이터 처리에 적합
- 구조가 단순하여 이해하기 쉬움
- 학습 목적/교육용으로 적합

단점:
- 긴 시퀀스에서 기울기 소실 문제
- 병렬 처리 불가 → 학습 느림
- Transformer 대비 성능 열세

예상 성능: 45~50%
```

#### KoBERT
```
구조: KoBERT Encoder → Pooling → Dense → Output

장점:
- 한국어 사전학습 모델
- 양방향 문맥 이해
- 형태소 단위 토크나이징

단점:
- GPU 메모리 많이 필요 (8GB+)
- 추론 속도 느림
- 모델 크기 큼 (약 350MB)

예상 성능: 52~55%
```

#### KoELECTRA (추천)
```
구조: KoELECTRA Encoder → Pooling → Dense → Output

장점:
- KoBERT 대비 4배 빠른 학습
- 적은 데이터로도 좋은 성능
- 경량화 버전 존재 (small, base)

단점:
- KoBERT 대비 약간 낮은 성능 (일부 태스크)

예상 성능: 50~55%
```

#### LightGBM + TF-IDF
```
구조: TF-IDF Vectorizer → LightGBM Classifier

장점:
- CPU만으로 빠른 학습/추론
- 해석 가능 (Feature Importance)
- 배포 간단

단점:
- 단어 순서/문맥 무시
- OOV(미등록 단어) 처리 어려움

예상 성능: 40~48%
```

**최종 추천:** KoELECTRA (성능 + 속도 균형)

---

### 9단계: 전체 리뷰 적용 (300,000개)

**방법:**
1. 8단계에서 선별된 모델로 학습 완료
2. 전체 300,000개 리뷰에 추론 적용
3. 결과 저장

**예상 소요 시간:**
| 모델 | 추론 시간 (300K) |
|------|-----------------|
| LSTM | ~2시간 |
| KoBERT | ~4시간 |
| KoELECTRA | ~2시간 |
| LightGBM | ~10분 |

**비용:** $0 (로컬 실행)

---

### 10단계: 연착륙 상품 분석

**분석 목표:**
> "6개월 이상 꾸준히 매출을 발생시키는 효자 상품" 발굴

**분석 기준:**

1. **스킨케어 카테고리 필터링**
   - 연착륙 제품의 83.3%가 스킨케어

2. **긍정 Aspect 기준**
   ```
   - 사용감/성능: positive 비율 높음
   - 재질/냄새: "자극 없음", "순함" 키워드
   - 재구매: positive 비율 높음
   ```

3. **부정 Aspect 회피**
   ```
   - 품질/퀄리티: negative 비율 낮음
   - 색상/발색: 기대 불일치 적음
   ```

**출력:**
- 연착륙 후보 상품 리스트
- 상품별 Aspect-Sentiment 분포
- B2B 입점 제안용 데이터

---

## 파일 구조

```
ABSA/
├── data/
│   ├── raw/
│   │   └── sampled_reviews_20k.csv      # 샘플링 데이터
│   ├── processed/
│   │   └── golden_set.xlsx              # Golden Set (430개)
│   └── batch/
│       ├── worker1_results.csv          # Worker 1 결과
│       ├── worker2_results.csv          # Worker 2 결과
│       └── pipeline_results_partial.csv # 누적 결과
├── openai_client.py                     # OpenAI API 클라이언트
├── batch_labeling.py                    # Batch API 라벨링
├── run_batch_pipeline.py                # 배치 파이프라인
├── run_parallel_batch.py                # 병렬 배치 처리
├── evaluate_model.py                    # 모델 평가
└── docs/
    └── ABSA_Pipeline_Documentation.md   # 이 문서
```

---

## 비용 요약

| 단계 | 모델 | 데이터 수 | 비용 |
|------|------|----------|------|
| 2단계 | GPT-4o-mini | 20,000 | $2.87 |
| 5단계 | GPT-4o | 430 (Golden Set) | ~$0.50 |
| 6단계 | GPT-4o Batch | 20,000 | $95.70 |
| 9단계 | ML 모델 | 300,000 | $0 |
| **총합** | | | **~$99** |

**GPT-4o로 300,000개 직접 라벨링 시:** ~$1,400
**절감액:** ~$1,300 (93% 절감)

---

## 다음 단계

1. [ ] 배치 작업 완료 대기
2. [ ] 결과 파일 병합
3. [ ] 샘플 검수 (100~200개)
4. [ ] ML 모델 학습 (KoELECTRA 추천)
5. [ ] 전체 데이터 적용
6. [ ] 연착륙 상품 분석

---

*문서 작성일: 2026-02-14*
*작성자: Claude Code*
