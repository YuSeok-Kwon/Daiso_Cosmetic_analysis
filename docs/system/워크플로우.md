## ABSA 데이터 정제 및 모델링 전략

제시해주신 세 가지 접근법에 대한 장단점을 프로젝트 문맥과 데이터 분석 효율성 관점에서 정리해 드립니다.

---

## ABSA 라벨링 수정 전략

### 1. [접근법 A] 규칙 기반 수정

#### 장점

- **비용 제로 ($0)**: 추가적인 API 호출이나 고성능 컴퓨팅 자원이 필요 없음
- **즉각성**: 정규표현식 등을 활용해 20,000건의 데이터를 몇 초 만에 수정할 수 있어 처리 속도가 가장 빠름
- **확실성**: 명확한 오타나 반복되는 태그 오류를 100% 정확하게 제거할 수 있음

#### 단점

- **확장성 한계**: "발림성"과 같이 문맥에 따라 다르게 해석될 수 있는 복잡한 오류는 규칙만으로 잡기 어려움
- **유연성 부족**: 예상치 못한 변칙적인 오답 패턴에는 대응할 수 없음

### 2. [접근법 B] 모델 재학습 후 재추론

#### 장점

- **정밀도 향상**: 직접 검수한 고품질 Gold set을 학습함으로써 모델이 도메인 특화(다이소 뷰티) 지식을 습득함
- **자동화된 문맥 파악**: 규칙으로 일일이 지정하기 힘든 복잡한 언어적 뉘앙스까지 모델이 스스로 학습하여 재분류함
- **지속 가능성**: 한 번 학습된 모델은 향후 추가되는 신규 리뷰 분석에도 그대로 활용 가능함

#### 단점

- **리소스 소요**: GPU 환경이 필수적이며, 학습 및 재추론을 위한 코딩과 시간이 소요됨
- **데이터 의존성**: Gold set의 품질이 낮으면 모델이 오답을 학습할 위험(Garbage In, Garbage Out)이 있음

### 3. [접근법 C] GPT 전체 재실행

#### 장점

- **최신 가이드 반영**: 속성 정의나 감성 점수 체계가 완전히 바뀌었을 때 가장 확실하게 데이터를 일원화할 수 있음
- **프롬프트 최적화**: 이전 시도에서 부족했던 지시사항을 보완하여 전체적인 품질을 한 번에 끌어올릴 수 있음

#### 단점

- **높은 비용**: API 비용이 추가로 발생하여 프로젝트 예산에 부담을 줌
- **시간 낭비**: 대량의 데이터를 다시 라벨링하고 검수하는 과정에서 프로젝트 일정이 지연될 수 있음

---
